{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "affecting-buyer",
   "metadata": {},
   "source": [
    "# Debug and Evaluate NN's performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-foster",
   "metadata": {},
   "source": [
    "Here we'll go deeper in examination of our model as much as we can. We are going to continue with the urls because they are unfamiliar, new and vary greatly. So no more interaction with our dataset.\n",
    "\n",
    "This is an extra multi-class classifiation task so we'll use the most popular method from statistics - working with samples. Here we'll evaluate something like a quarter of the whole dataset or $\\approx$ 25-30 breeds. \n",
    "\n",
    "We are going to sample 'neighbors' since most of the similar labels stand next to each other. For example look at breeds labeled 98 and 99 - malamute and siberian husky. They are pretty much alike and confusing. The same with Shih Tsu and Pekinese standing on 3 and 4. This has been the story of our dataset. \n",
    "\n",
    "If we get a general metric like accuracy of something like 85-91% or even a bit less, since that was our result on data/validation, on completely new data, then the 'randomness' and representativity has been successful.\n",
    "\n",
    "I built a simple web application that will serve as a better way to get, put and test data and even gather more for future continuation with the currect model. Feel free to go and check it yourself, the link is on the bottom of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "curious-dynamics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.applications import inception_resnet_v2\n",
    "\n",
    "\n",
    "import pickle\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-structure",
   "metadata": {},
   "source": [
    "Let's load our work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "convinced-probe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('saved_model-20210201T203511Z-001/saved_model/resnet_inception')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "listed-standing",
   "metadata": {},
   "outputs": [],
   "source": [
    "opener = open('dict_of_labels.pickle', 'rb')\n",
    "named_labels = pickle.load(opener)\n",
    "opener.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generic-chester",
   "metadata": {},
   "source": [
    "Here the idea is simple. We are just going to slightly modify our function 'give top three prediction' from part 3. We'll get the first suggestion of our model and analyze it this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "everyday-custom",
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_index(pic, model, named_labels=named_labels):\n",
    "  picture = resize(pic, (299, 299), preserve_range = True)\n",
    "  picture = tf.keras.applications.inception_resnet_v2.preprocess_input(picture)\n",
    "  picture = tf.expand_dims(picture, axis = 0)\n",
    "  predictions = model.predict(picture)\n",
    "  prediction = max(predictions[0])\n",
    "  index1 = list(predictions[0]).index(prediction)\n",
    "  return index1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automatic-cannon",
   "metadata": {},
   "source": [
    "Now I prepared from google search a few links for each label. Some of them are easy, some of them have other objects, some of them with 2 or 3 of the same species in the picture, some picture might not even be read due to some error/forbidden. We'll put them in two mirror arrays and work with them later for stuff like accuracy, confusion matrices, easy and difficult classes and features from our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "frozen-english",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_table('test.txt', sep=';', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fluid-charleston",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns = ['url', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "broad-district",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The results we'll examine as explained\n",
    "\n",
    "predicted = []\n",
    "actual = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "preliminary-schema",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f52a6396e18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f52a6396e18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Predicted: 100 vs Actual: 100\n",
      "Predicted: 100 vs Actual: 100\n",
      "Predicted: 100 vs Actual: 100\n",
      "broken image\n",
      "Predicted: 100 vs Actual: 100\n",
      "Predicted: 100 vs Actual: 100\n",
      "Predicted: 9 vs Actual: 9\n",
      "Predicted: 9 vs Actual: 9\n",
      "Predicted: 9 vs Actual: 9\n",
      "Predicted: 9 vs Actual: 9\n",
      "broken image\n",
      "Predicted: 9 vs Actual: 9\n",
      "Predicted: 119 vs Actual: 119\n",
      "Predicted: 119 vs Actual: 119\n",
      "Predicted: 119 vs Actual: 119\n",
      "Predicted: 119 vs Actual: 119\n",
      "Predicted: 119 vs Actual: 119\n",
      "Predicted: 119 vs Actual: 119\n",
      "Predicted: 40 vs Actual: 40\n",
      "Predicted: 38 vs Actual: 40\n",
      "Predicted: 40 vs Actual: 40\n",
      "Predicted: 40 vs Actual: 40\n",
      "Predicted: 40 vs Actual: 40\n",
      "Predicted: 40 vs Actual: 40\n",
      "Predicted: 29 vs Actual: 29\n",
      "Predicted: 29 vs Actual: 29\n",
      "Predicted: 28 vs Actual: 29\n",
      "Predicted: 29 vs Actual: 29\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 299, 299, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='sequential_4_input'), name='sequential_4_input', description=\"created by layer 'sequential_4_input'\"), but it was called on an input with incompatible shape (None, 299, 299, 4).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 299, 299, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='random_flip_2_input'), name='random_flip_2_input', description=\"created by layer 'random_flip_2_input'\"), but it was called on an input with incompatible shape (None, 299, 299, 4).\n",
      "broken image\n",
      "Predicted: 91 vs Actual: 29\n",
      "Predicted: 90 vs Actual: 89\n",
      "Predicted: 89 vs Actual: 89\n",
      "Predicted: 89 vs Actual: 89\n",
      "Predicted: 90 vs Actual: 89\n",
      "Predicted: 90 vs Actual: 89\n",
      "Predicted: 89 vs Actual: 89\n",
      "Predicted: 42 vs Actual: 42\n",
      "Predicted: 42 vs Actual: 42\n",
      "Predicted: 42 vs Actual: 42\n",
      "Predicted: 42 vs Actual: 42\n",
      "Predicted: 42 vs Actual: 42\n",
      "Predicted: 42 vs Actual: 42\n",
      "Predicted: 101 vs Actual: 101\n",
      "broken image\n",
      "Predicted: 101 vs Actual: 101\n",
      "Predicted: 101 vs Actual: 101\n",
      "broken image\n",
      "Predicted: 101 vs Actual: 101\n",
      "Predicted: 10 vs Actual: 10\n",
      "Predicted: 10 vs Actual: 10\n",
      "Predicted: 10 vs Actual: 10\n",
      "Predicted: 10 vs Actual: 10\n",
      "Predicted: 10 vs Actual: 10\n",
      "Predicted: 10 vs Actual: 10\n",
      "broken image\n",
      "Predicted: 16 vs Actual: 11\n",
      "Predicted: 11 vs Actual: 11\n",
      "Predicted: 11 vs Actual: 11\n",
      "Predicted: 11 vs Actual: 11\n",
      "Predicted: 11 vs Actual: 11\n",
      "Predicted: 30 vs Actual: 30\n",
      "Predicted: 30 vs Actual: 30\n",
      "Predicted: 30 vs Actual: 30\n",
      "Predicted: 0 vs Actual: 0\n",
      "Predicted: 0 vs Actual: 0\n",
      "Predicted: 0 vs Actual: 0\n",
      "Predicted: 6 vs Actual: 0\n",
      "Predicted: 1 vs Actual: 1\n",
      "Predicted: 1 vs Actual: 1\n",
      "broken image\n",
      "Predicted: 1 vs Actual: 1\n",
      "broken image\n",
      "Predicted: 2 vs Actual: 2\n",
      "Predicted: 2 vs Actual: 2\n",
      "Predicted: 3 vs Actual: 3\n",
      "Predicted: 3 vs Actual: 3\n",
      "broken image\n",
      "Predicted: 4 vs Actual: 4\n",
      "broken image\n",
      "Predicted: 4 vs Actual: 4\n",
      "Predicted: 5 vs Actual: 5\n",
      "Predicted: 5 vs Actual: 5\n",
      "Predicted: 5 vs Actual: 5\n",
      "Predicted: 6 vs Actual: 6\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 299, 299, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='sequential_4_input'), name='sequential_4_input', description=\"created by layer 'sequential_4_input'\"), but it was called on an input with incompatible shape (None, 299, 299, 4).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 299, 299, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='random_flip_2_input'), name='random_flip_2_input', description=\"created by layer 'random_flip_2_input'\"), but it was called on an input with incompatible shape (None, 299, 299, 4).\n",
      "broken image\n",
      "Predicted: 7 vs Actual: 7\n",
      "Predicted: 7 vs Actual: 7\n",
      "Predicted: 7 vs Actual: 7\n",
      "Predicted: 8 vs Actual: 8\n",
      "Predicted: 8 vs Actual: 8\n",
      "Predicted: 8 vs Actual: 8\n",
      "broken image\n",
      "Predicted: 12 vs Actual: 12\n",
      "Predicted: 12 vs Actual: 12\n",
      "Predicted: 13 vs Actual: 13\n",
      "Predicted: 13 vs Actual: 13\n",
      "Predicted: 13 vs Actual: 13\n",
      "broken image\n",
      "Predicted: 14 vs Actual: 14\n",
      "Predicted: 14 vs Actual: 14\n",
      "Predicted: 45 vs Actual: 45\n",
      "Predicted: 47 vs Actual: 45\n",
      "Predicted: 45 vs Actual: 45\n",
      "Predicted: 106 vs Actual: 97\n",
      "Predicted: 106 vs Actual: 97\n",
      "Predicted: 106 vs Actual: 97\n",
      "Predicted: 98 vs Actual: 98\n",
      "Predicted: 98 vs Actual: 98\n",
      "broken image\n",
      "Predicted: 99 vs Actual: 99\n",
      "Predicted: 97 vs Actual: 99\n",
      "Predicted: 97 vs Actual: 99\n",
      "Predicted: 43 vs Actual: 43\n",
      "broken image\n",
      "broken image\n",
      "broken image\n",
      "Predicted: 44 vs Actual: 44\n",
      "Predicted: 44 vs Actual: 44\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "for t in test['url']:\n",
    "    try:\n",
    "        pred = give_index(imread(t), model, named_labels)\n",
    "        act = test['label'][num]\n",
    "        print(f\"Predicted: {pred} vs Actual: {act}\")\n",
    "        predicted.append(pred)\n",
    "        actual.append(act)\n",
    "    except:\n",
    "        print('broken image')\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "divided-holocaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "silver-trial",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "informal-station",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.13861203193665"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(predicted, actual).numpy() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-wound",
   "metadata": {},
   "source": [
    "So this accuracy is pretty much the same with what we achieved in the previous notebook. They are not that many example so I printed them and something interesting popped up. It confused label 106(Eskimo Dog) with Samoyed. Google them if you want, they look absolutely the same to mee too. The rest of the predictions are pretty standard with very few exceptions so let's focus on this interesting case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mounted-solution",
   "metadata": {},
   "source": [
    "Let's feed our model with more of this two breeds. Will it classify all as Samoyed. Or it is really exracting good features. This will be a great opportunity to look inside the convolutions as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "contrary-modem",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load few samoyeds. Remember, samoyed is 106, eskimo is 97.\n",
    "\n",
    "samoyed1 = imread('https://d17fnq9dkz9hgj.cloudfront.net/breed-uploads/2018/08/samoyed-card-small.jpg?bust=1535568014')\n",
    "# samoyed2 = imread('https://www.purina.com.au/-/media/project/purina/main/breeds/puppies/puppy-samoyed.jpg')\n",
    "samoyed3 = imread('https://images.ctfassets.net/440y9b545yd9/49v1AZmZdiPYkJ4A3vrayj/d7d7db21fed2ef30f5b8e3899633d292/Samoyed850.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "interested-likelihood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n",
      "106\n"
     ]
    }
   ],
   "source": [
    "print(give_index(samoyed1, model, named_labels))\n",
    "# print(give_index(samoyed2, model, named_labels))\n",
    "print(give_index(samoyed3, model, named_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-visit",
   "metadata": {},
   "source": [
    "Hmm, it keeps insisting with the samoyed. The bell is starting to ring. Let's load more eskimos and see if it will be able to classify them correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "legal-algebra",
   "metadata": {},
   "outputs": [],
   "source": [
    "eskimo1 = imread('https://dgicdplf3pvka.cloudfront.net/images/dogbreeds/large/American-Eskimo-Dog.jpg')\n",
    "eskimo2 = imread('https://www.dogzone.com/images/breeds/american-eskimo-dog-800.jpg')\n",
    "eskimo3 = imread('https://fwkc-cloudinary.corebine.com/fwkc-production/image/upload/v1/fwkc-prod/EskimoDog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "virgin-shooting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n",
      "106\n",
      "106\n"
     ]
    }
   ],
   "source": [
    "print(give_index(eskimo1, model, named_labels))\n",
    "print(give_index(eskimo2, model, named_labels))\n",
    "print(give_index(eskimo3, model, named_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earned-homework",
   "metadata": {},
   "source": [
    "Are we going to completely ignore the eskimo label? Let's try one last time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cultural-postage",
   "metadata": {},
   "outputs": [],
   "source": [
    "eskimo4 = imread('http://knowledgebase.lookseek.com/images/animals/dogs/American-Eskimo-Dog.jpg')\n",
    "eskimo5 = imread('https://www.timeforpaws.co.uk/img/American-Eskimo.jpg')\n",
    "eskimo6 = imread('https://i.pinimg.com/originals/aa/61/d2/aa61d2e6c36d7446c66133ad03ad2cb2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "historical-surfing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n",
      "106\n",
      "106\n"
     ]
    }
   ],
   "source": [
    "print(give_index(eskimo4, model, named_labels))\n",
    "print(give_index(eskimo5, model, named_labels))\n",
    "print(give_index(eskimo6, model, named_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-sullivan",
   "metadata": {},
   "source": [
    "Aparently we were lucky enough to probably find the biggest confusion in our model. It completely ignores class 97 and goes for mostly 106 but even confuses it with 107(Pomeranian) which is a different color. It's true that I'm not a dog expert but out of more than 10 pictures from google, most of them at the very beginning of the search results, at least one should be actually Eskimo so we have a problem, it's not a mistake.\n",
    "\n",
    "We can actually use our Top K Accuracy that we evaluated as very good from the previous notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "lovely-affair",
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_top_three_candidates(pic, model, named_labels=named_labels):\n",
    "  picture = resize(pic, (299, 299), preserve_range = True)\n",
    "  picture = tf.keras.applications.inception_resnet_v2.preprocess_input(picture)\n",
    "  picture = tf.expand_dims(picture, axis = 0)\n",
    "  predictions = model.predict(picture)\n",
    "  score = ''\n",
    "  prediction = max(predictions[0])\n",
    "  index1 = list(predictions[0]).index(prediction)\n",
    "  predictions[0][index1] = 0\n",
    "  score += f'This is a {named_labels[index1]} with {round((100 * prediction), 2)} % certainty'\n",
    "  score += '\\n'\n",
    "  prediction = max(predictions[0])\n",
    "  index2 = list(predictions[0]).index(prediction)\n",
    "  score += f'Second guess is {named_labels[index2]} with {round((100 * prediction), 2)} % certainty'\n",
    "  score += \"\\n\"\n",
    "  predictions[0][index2] = 0\n",
    "  prediction = max(predictions[0])\n",
    "  index3 = list(predictions[0]).index(prediction)\n",
    "  score += f'Third guess is {named_labels[index3]} with {round((100 * prediction), 2)} % certainty'\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "manufactured-villa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a Samoyed with 97.07 % certainty\n",
      "Second guess is Great_Pyrenees with 0.96 % certainty\n",
      "Third guess is kuvasz with 0.28 % certainty\n",
      "----------------------------------\n",
      "This is a Samoyed with 97.13 % certainty\n",
      "Second guess is Pomeranian with 0.32 % certainty\n",
      "Third guess is Great_Pyrenees with 0.29 % certainty\n",
      "----------------------------------\n",
      "This is a Samoyed with 92.52 % certainty\n",
      "Second guess is Pomeranian with 4.46 % certainty\n",
      "Third guess is keeshond with 1.31 % certainty\n",
      "----------------------------------\n",
      "This is a Pomeranian with 62.88 % certainty\n",
      "Second guess is Samoyed with 30.21 % certainty\n",
      "Third guess is keeshond with 3.14 % certainty\n",
      "----------------------------------\n",
      "This is a Samoyed with 52.47 % certainty\n",
      "Second guess is golden_retriever with 7.88 % certainty\n",
      "Third guess is Great_Pyrenees with 6.05 % certainty\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(give_top_three_candidates(eskimo1, model, named_labels))\n",
    "print('----------------------------------')\n",
    "print(give_top_three_candidates(eskimo2, model, named_labels))\n",
    "print('----------------------------------')\n",
    "print(give_top_three_candidates(eskimo3, model, named_labels))\n",
    "print('----------------------------------')\n",
    "print(give_top_three_candidates(eskimo4, model, named_labels))\n",
    "print('----------------------------------')\n",
    "print(give_top_three_candidates(eskimo6, model, named_labels))\n",
    "print('----------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-accused",
   "metadata": {},
   "source": [
    "We found a very big problem with this class, it hasn't even appeared once in its top 3 suggestions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-general",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We verified the general performance of our neural network. The accuracy of around 90% for the 120 breeds from Stanford Dogs dataset in general is a fair assessment. We achieved those numbers in training(87%), validation(91.5%) and testing(86.5%). Here we hit probably the biggest confusion wall of all in Samoyed-Eskimo Dog case so the accuracy actually must be higher than that given that and the fact that we didn't select some of the easiest breeds.\n",
    "\n",
    "There should also be other difficulties with the dataset between hardly distinguishable breeds. In order to verify that and to improve our model I created a simple web application. \n",
    "\n",
    "Go to - [this link](http://ec2-54-184-171-180.us-west-2.compute.amazonaws.com/) - to check it. \n",
    "\n",
    "For now this is it. As you can see doing manually this process is very tedious. It took awhile to make this for 20 breeds, we have another 100.. and these 120 breeds are not even 50% of the existing. The dataset was also far from perfect from what we saw."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-humidity",
   "metadata": {},
   "source": [
    "## For the future \n",
    "\n",
    "1) Use the Web App to gather more data easily\n",
    "\n",
    "2) Use it to evaluate and locate other problematic breeds\n",
    "\n",
    "3) Train the model again focusing on the problematic breeds and its features\n",
    "\n",
    "4) Add new breeds\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda6ac3eb640aa240f5b6eadab3e8e24e77"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}